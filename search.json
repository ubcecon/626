[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "This site was created using Quarto.\nSource code is available on github with a CC-by-SA license."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "ECON 626: Econometric Theory I",
    "section": "",
    "text": "Part II: Generalized Linear Model\n\nPreliminaries of Projection Geometry\nGeneralized Linear Models and Gauss-Markov Theorem\nTests of Linear Hypothesis\n\n\n\nPart III: Tools of Asymptotic Theory\n\nModes of Convergence\nSlutsky’s Lemma/Continuous Mapping Theorem\nDelta Methods\n\n\n\nPart V: Linear Models with Endogeneity\n\nIdentification and Endogeneity\nIdentification through IV and Inference\n\n\n\n\n\n\nReferences\n\nÇinlar, Erhan. 2011. Probability and Stochastics. Vol. 261. Springer.\n\n\nPollard, David. 2002. A User’s Guide to Measure Theoretic Probability. 8. Cambridge University Press.\n\n\nSong, Kyunchul. 2021. “Introduction to Econometrics.”\n\n\nTao, Terence. 2011. An Introduction to Measure Theory. Vol. 126. American Mathematical Society Providence."
  },
  {
    "objectID": "inference/inference.html#reading",
    "href": "inference/inference.html#reading",
    "title": "Inference",
    "section": "Reading",
    "text": "Reading\n\nSong (2021) chapter 4 (which is the basis for these slides)\n\\[\n\\def\\Er{{\\mathrm{E}}}\n\\def\\R{{\\mathbb{R}}}\n\\]"
  },
  {
    "objectID": "measure/measure.html#references",
    "href": "measure/measure.html#references",
    "title": "Measure",
    "section": "References",
    "text": "References\n\nSong (2021) chapter 1 (which is the basis for these slides)\nPollard (2002)\nTao (2011)"
  },
  {
    "objectID": "measure/measure.html#why-measure-theory",
    "href": "measure/measure.html#why-measure-theory",
    "title": "Measure",
    "section": "Why Measure Theory?",
    "text": "Why Measure Theory?\n\n\nSimplifies some arguments\n\nExample from Pollard (2002), define independence as factorization of distribution functions \\[ P(X \\leq x \\cap Y \\leq y) = P(X \\leq x) P(Y \\leq y) \\]\nIf \\(X_1,X_2,X_3, X_4\\) are independent, show that \\[ Y = X_1 X_2 \\log\\left(\\frac{X_1^2 + X_2^3}{|X_1| + |X_2|}\\right) \\] is independent of \\[ Z =  sin\\left(X_3 + X_3^2 + X_3X_4 + X_4^2 \\right) \\]"
  },
  {
    "objectID": "measure/measure.html#why-measure-theory-1",
    "href": "measure/measure.html#why-measure-theory-1",
    "title": "Measure",
    "section": "Why Measure Theory?",
    "text": "Why Measure Theory?\n\nSimplifies some arguments\n\n\n\nUnifies treatment\n\ndiscrete vs continuous\nuni- vs multi-variate\n\nResolves some difficulties with infinity"
  },
  {
    "objectID": "measure/measure.html#measure-space",
    "href": "measure/measure.html#measure-space",
    "title": "Measure",
    "section": "Measure Space",
    "text": "Measure Space\n\n\nA set \\(\\Omega\\)\nA collection of subsets, \\(\\mathscr{F}\\), of \\(\\Omega\\) that is a \\(\\sigma\\)-field (aka \\(\\sigma\\)-algebra) , that is\n\n\\(\\Omega \\in \\mathscr{F}\\)\nIf \\(A \\in \\mathscr{F}\\), then \\(A^c \\in \\mathscr{F}\\)\nIf \\(A_1, A_2, ... \\in \\mathscr{F}\\), then \\(\\cup_{j=1}^\\infty A_j \\in \\mathscr{F}\\)\n\nA measure, \\(\\mu: \\mathcal{F} \\to [0, \\infty]\\) s.t.\n\n\\(\\mu(\\emptyset) = 0\\)\nIf \\(A_1, A_2, ... \\in \\mathscr{F}\\) are pairwise disjoint, then \\(\\mu\\left(\\cup_{j=1}^\\infty A_j \\right) = \\sum_{j=1}^\\infty \\mu(A_j)\\)\n\n\n\n\nExample of sigma fields"
  },
  {
    "objectID": "measure/measure.html#measurable-function",
    "href": "measure/measure.html#measurable-function",
    "title": "Measure",
    "section": "Measurable Function",
    "text": "Measurable Function\n\nGiven a topology on \\(\\Omega\\), the Borel \\(\\sigma\\)-field, \\(\\mathscr{B}(\\Omega)\\), is the smallest \\(\\sigma\\)-field containing all open subsets of \\(\\Omega\\)\n\n\nWhen working with \\(R^d\\), we will generally use \\(\\mathscr{B}(\\mathbf{R}^d)\\) as our \\(\\sigma\\)-field.\n\n\n\\(f: \\Omega \\to \\mathbf{R}\\) is (\\(\\mathscr{F}\\)-)measurable if \\(\\forall\\) \\(B \\in \\mathscr{B}(\\mathbf{R})\\), \\(f^{-1}(B) \\in \\mathscr{F}\\)\na statement holds almost everywhere (a.e.) if the measure of the set where the statement is false is 0"
  },
  {
    "objectID": "measure/measure.html#simple-functions",
    "href": "measure/measure.html#simple-functions",
    "title": "Measure",
    "section": "Simple Functions",
    "text": "Simple Functions\n\nAssume \\(\\mu(\\Omega) < \\infty\\)\n\\(f\\) is a simple function if \\(f = \\sum_{j=1}^n a_j 1\\{\\omega \\in E_j \\}\\) for \\(a_j \\in \\mathbf{R}\\) and \\(E_j \\in \\mathscr{F}\\)\nIntegral of simple functions: \\[ \\int f d \\mu = \\sum_{j=1}^n a_j \\mu(E_j) \\]"
  },
  {
    "objectID": "measure/measure.html#bounded-functions",
    "href": "measure/measure.html#bounded-functions",
    "title": "Measure",
    "section": "Bounded Functions",
    "text": "Bounded Functions\n\nLet \\(E\\) be such that \\(\\mu(E)<\\infty\\)\nLet \\(f\\) be bounded function and \\(f(x) = 0 \\forall x \\in E^c\\)\nDefine: \\[\n\\int f d\\mu \\equiv \\sup_{\\varphi \\leq f: \\varphi \\text{ simple}} \\int \\varphi d\\mu =\\inf_{\\varphi \\geq f: \\varphi \\text{ simple}} \\int \\varphi d\\mu\n\\]"
  },
  {
    "objectID": "measure/measure.html#section",
    "href": "measure/measure.html#section",
    "title": "Measure",
    "section": "",
    "text": "Exercise\n\n\nShow that for all bounded \\(f\\) and \\(g\\) that vanish outside a finite measure set,\n\nIf \\(f \\geq 0\\) a.e., then \\(\\int f d\\mu \\geq 0\\)\n\\(\\forall a \\in \\mathbf{R}\\) , \\(\\int a f d\\mu = a \\int f d\\mu\\)\n\\(\\int (f + g) d\\mu = \\int f d\\mu + \\int g d \\mu\\)"
  },
  {
    "objectID": "measure/measure.html#nonnegative-functions",
    "href": "measure/measure.html#nonnegative-functions",
    "title": "Measure",
    "section": "Nonnegative Functions",
    "text": "Nonnegative Functions\n\nIf \\(f \\geq 0\\), define \\[\n\\int fd\\mu =\\sup_{f_n \\leq f \\text{ simple, bounded+}} \\int f_{n}d\\mu\n\\]"
  },
  {
    "objectID": "measure/measure.html#measurable-functions",
    "href": "measure/measure.html#measurable-functions",
    "title": "Measure",
    "section": "Measurable Functions",
    "text": "Measurable Functions\n\nIf \\(f\\) is measurable, let \\(f^{+} = \\max\\{f, 0\\}\\) and \\(f^{-} = \\max\\{-f, 0\\}\\) and define the Lesbegue integral\n\n\\[ \\int f d\\mu = \\int f^{+} d\\mu - \\int f^{-} d\\mu \\]"
  },
  {
    "objectID": "measure/measure.html#finite-measure",
    "href": "measure/measure.html#finite-measure",
    "title": "Measure",
    "section": "Finite Measure",
    "text": "Finite Measure\n\nMeasure \\(\\mu\\) is finite if \\(\\mu(\\Omega)\\) is finite\n\\(\\mu\\) is \\(\\sigma\\)-finite if \\(\\exists\\) \\(\\{A_n\\}_{n=1}^\\infty \\in \\mathscr{F}\\) s.t. \\(\\mu(A_n)\\) is finite \\(\\forall n\\) and \\(\\cup_{n=1}^\\infty A_n = \\Omega\\)\n\n\n\n\nExercise\n\n\nLet \\(\\Omega\\) be countable with any \\(\\mathscr{F}\\), define \\(\\mu(A)\\) as the number of elements of \\(A\\). Show \\(\\mu\\) is \\(\\sigma\\) finite."
  },
  {
    "objectID": "measure/measure.html#lebesgue-measure",
    "href": "measure/measure.html#lebesgue-measure",
    "title": "Measure",
    "section": "Lebesgue Measure",
    "text": "Lebesgue Measure\n\n\n\nTheorem\n\n\nThere exists a unique \\(\\sigma\\)-finite measure \\(\\mu\\) on \\((\\mathbf{R},\\mathscr{B}(\\mathbf{R}))\\) such that for any \\(a\\leq b\\) with \\(a,b\\in \\mathbf{R}\\), \\[\n\\mu ((a,b])=b-a\n\\]"
  },
  {
    "objectID": "measure/measure.html#absolute-continuity",
    "href": "measure/measure.html#absolute-continuity",
    "title": "Measure",
    "section": "Absolute Continuity",
    "text": "Absolute Continuity\n\nMeasure \\(\\nu\\) is absolutely continuous with respect to \\(\\mu\\) if for \\(A \\in \\mathscr{F}\\), \\(\\mu(A) = 0\\) implies \\(\\nu(A) = 0\\)\n\ndenotate as \\(\\nu \\ll \\mu\\)\n\\(\\mu\\) is called a dominating measure\n\n\n\nRelation with continuity?"
  },
  {
    "objectID": "measure/measure.html#radon-nikodym-derivative",
    "href": "measure/measure.html#radon-nikodym-derivative",
    "title": "Measure",
    "section": "Radon-Nikodym Derivative",
    "text": "Radon-Nikodym Derivative\n\n\n\nTheorem\n\n\nLet \\((\\Omega,\\mathscr{F},\\mu)\\) be a measure space, and let \\(\\nu\\) and \\(\\mu\\) be \\(\\sigma\\)-finite measures defined on \\(\\mathscr{F}\\) and \\(\\nu \\ll \\mu\\). Then there is a nonnegative measurable function \\(f\\) such that for each set \\(A\\in \\mathscr{F}\\), \\[\n\\nu (A)=\\int_{A}fd\\mu\n\\] For any such \\(f\\) and \\(g\\), \\(\\mu (\\{\\omega \\in \\Omega:f(\\omega )\\neq g(\\omega )\\})=0\\)\n\n\n\n\nDenote $f = \nExercise: show coincides with usual derivative?"
  },
  {
    "objectID": "measure/measure.html#sequences-of-sets",
    "href": "measure/measure.html#sequences-of-sets",
    "title": "Measure",
    "section": "Sequences of Sets",
    "text": "Sequences of Sets\n\n\\(\\{E_n\\}_{n \\geq 1} \\in \\mathscr{F}\\)\n\nincreasing if \\(E_1 \\subset E_2 \\subset ...\\)\ndecreasing if \\(E_1 \\supset E_2 \\supset ...\\)\nmonotone if either increasing or decreasing\n\nFor increasing \\(E_n\\), define \\(\\lim_{n \\to \\infty} E_n =\\cup_{n=1}^\\infty E_n\\)\nFor decreasing \\(E_n\\), define \\(\\lim_{n \\to \\infty} E_n =\\cap_{n=1}^\\infty E_n\\)"
  },
  {
    "objectID": "measure/measure.html#continuity-of-measure",
    "href": "measure/measure.html#continuity-of-measure",
    "title": "Measure",
    "section": "Continuity of Measure",
    "text": "Continuity of Measure\n\n\n\nLemma\n\n\nSuppose that \\(\\{E_{n}\\}\\) is a monotone sequence of events. Then \\[\n\\mu \\left( \\lim_{n\\rightarrow \\infty}E_{n}\\right) =\\lim_{n\\rightarrow \\infty }\\mu (E_{n}).\n\\]"
  },
  {
    "objectID": "measure/measure.html#monotone-convergence-theorem",
    "href": "measure/measure.html#monotone-convergence-theorem",
    "title": "Measure",
    "section": "Monotone Convergence Theorem",
    "text": "Monotone Convergence Theorem\n\n\n\nLemma\n\n\nIf \\(f_n:\\Omega \\to \\mathbf{R}\\) are measurable, \\(f_{n}\\geq 0\\), and for each \\(\\omega \\in \\Omega\\), \\(f_{n}(\\omega )\\uparrow f(\\omega )\\), then \\(\\int f_{n}d\\mu \\uparrow \\int fd\\mu\\) as \\(n\\rightarrow \\infty\\)"
  },
  {
    "objectID": "measure/measure.html#fatous-lemma",
    "href": "measure/measure.html#fatous-lemma",
    "title": "Measure",
    "section": "Fatou’s Lemma",
    "text": "Fatou’s Lemma\n\n\n\nLemma\n\n\nIf \\(f_n:\\Omega \\to \\mathbf{R}\\) are measurable, \\(f_{n}\\geq 0\\), then \\[\n\\int \\left( \\text{liminf}_{n\\rightarrow \\infty }f_{n}d\\mu \\right) \\leq \\text{liminf}_{n\\rightarrow \\infty }\\int f_{n}d\\mu\n\\]"
  },
  {
    "objectID": "measure/measure.html#dominated-convergence-theorem",
    "href": "measure/measure.html#dominated-convergence-theorem",
    "title": "Measure",
    "section": "Dominated Convergence Theorem",
    "text": "Dominated Convergence Theorem\n\n\n\nLemma\n\n\nIf \\(f_n:\\Omega \\to \\mathbf{R}\\) are measurable, and for each \\(\\omega \\in \\Omega\\), \\(f_{n}(\\omega )\\rightarrow f(\\omega ).\\) Furthermore, for some \\(g\\geq 0\\) such that \\(\\int gd\\mu <\\infty\\), \\(|f_{n}|\\leq g\\) for each \\(n\\geq 1\\). Then, \\(\\int f_{n}d\\mu \\rightarrow \\int fd\\mu\\)\n\n\n\n\nThe measurable condition here can be dropped and outermeasure used instead. This simplifies some proofs in asymptotic theory."
  },
  {
    "objectID": "probability/probability.html#reading",
    "href": "probability/probability.html#reading",
    "title": "Probability",
    "section": "Reading",
    "text": "Reading\n\nSong (2021) chapter 2 (which is the basis for these slides)\nPollard (2002)\n\n\\[\n\\def\\Er{{\\mathrm{E}}}\n\\def\\R{{\\mathbb{R}}}\n\\]"
  },
  {
    "objectID": "probability/probability.html#probability-space",
    "href": "probability/probability.html#probability-space",
    "title": "Probability",
    "section": "Probability Space",
    "text": "Probability Space\n\n\n\nDefinitions\n\n\n\nGiven a measure space \\((\\Omega ,\\mathscr{F})\\), a probability (or probability measure)\\(\\ P\\) is a measure s.t. \\(P(\\Omega )=1\\)\n\\((\\Omega ,\\mathscr{F}, P)\\) is a probability space\n\\(\\Omega\\) is a sample space\n\\(\\omega \\in \\Omega\\) is an outcome\n\\(A \\in \\mathscr{F}\\) is an event"
  },
  {
    "objectID": "probability/probability.html#random-variable",
    "href": "probability/probability.html#random-variable",
    "title": "Probability",
    "section": "Random Variable",
    "text": "Random Variable\n\n\n\nDefinition\n\n\nA random variable \\(X\\) is a measurable function from \\(\\Omega\\) to \\(\\mathbf{R}\\)"
  },
  {
    "objectID": "probability/probability.html#distribution",
    "href": "probability/probability.html#distribution",
    "title": "Probability",
    "section": "Distribution",
    "text": "Distribution\n\n\n\nDefinition\n\n\nLet \\((\\Omega ,\\mathscr{F},P)\\) be a probability space, \\(X\\) a random variable on \\((\\Omega ,\\mathscr{F})\\). A distribution \\(P_{X}\\) induced by \\(X\\) is a probability measure on \\((\\mathbf{R},\\mathscr{B}(\\mathbf{R}))\\) such that : \\(\\forall B\\in \\mathscr{B}(\\mathbf{R})\\), \\[\nP_{X}(B)\\equiv P\\left\\{ \\omega \\in \\Omega :X(\\omega )\\in B\\right\\}\n\\]"
  },
  {
    "objectID": "probability/probability.html#distribution-function",
    "href": "probability/probability.html#distribution-function",
    "title": "Probability",
    "section": "Distribution Function",
    "text": "Distribution Function\n\n\n\nDefinition\n\n\nThe CDF of a random variable \\(X\\) with distribution \\(P_{X}\\) is defined to be a function \\(F:\\mathbf{R}\\rightarrow [0,1]\\) such that \\[\nF(t)=P_{X}\\left( (-\\infty ,t]\\right) .\n\\]"
  },
  {
    "objectID": "probability/probability.html#stochastic-dominance",
    "href": "probability/probability.html#stochastic-dominance",
    "title": "Probability",
    "section": "Stochastic Dominance",
    "text": "Stochastic Dominance\n\n\n\nDefinition\n\n\nSuppose that two random variables \\(X_1\\) and \\(X_2\\) have CDFs \\(F_1\\) and \\(F_2\\).\n\nSuppose that \\(F_1(x) \\le F_2(x)\\) for all \\(x \\in \\mathbf{R}\\). Then \\(X_1\\) first order stochastically dominates (FOSD) \\(X_2\\).\nSuppose that for all \\(y \\in \\mathbf{R}\\), \\[\n     \\int_{-\\infty}^y F_1(x) dx \\le \\int_{-\\infty}^y F_2(x) dx.\n\\] Then \\(X_1\\) second order stochastically dominates (SOSD) \\(X_2\\)"
  },
  {
    "objectID": "probability/probability.html#density",
    "href": "probability/probability.html#density",
    "title": "Probability",
    "section": "Density",
    "text": "Density\n\n\n\nDefinition\n\n\n\nLet \\(X\\) be a random variable with distribution \\(P_{X}\\). When \\(P_{X}\\ll \\lambda\\), we call \\(X\\) a continuous random variable, and call the Radon-Nikodym derivative \\(f\\equiv dP_{X}/d\\lambda\\) the (probability) density function of \\(P_{X}\\).\nWe say that \\(X\\) is a discrete random variable, if there exists a countable set \\(A\\subset \\mathbf{R}\\) and such that \\(P_{X}A^{c}=0\\)\n\n\n\n\n\nDensity wrt to other measures? e.g. dirac?"
  },
  {
    "objectID": "probability/probability.html#markovs",
    "href": "probability/probability.html#markovs",
    "title": "Probability",
    "section": "Markov’s",
    "text": "Markov’s\n\n\n\nMarkov’s Inequality\n\n\n\\(P(|X|>\\epsilon) \\leq \\frac{\\Er[|X|^k]}{\\epsilon^k}\\) \\(\\forall \\epsilon > 0, k > 0\\)"
  },
  {
    "objectID": "probability/probability.html#jensens",
    "href": "probability/probability.html#jensens",
    "title": "Probability",
    "section": "Jensen’s",
    "text": "Jensen’s\n\n\n\nJensen’s Inequality\n\n\nSuppose that \\(g\\) is convex and \\(X\\) and \\(g(X)\\) are integrable, then \\(g(\\Er X) \\leq \\Er[g(X)]\\)\n\n\n\n\n\n\nExercise\n\n\nShow \\(\\Er[|X|^p] \\leq \\left(\\Er[|X|^q] \\right)^{p/q}\\) for all \\(0 < p \\leq q\\)."
  },
  {
    "objectID": "probability/probability.html#cauchy-schwarz",
    "href": "probability/probability.html#cauchy-schwarz",
    "title": "Probability",
    "section": "Cauchy-Schwarz",
    "text": "Cauchy-Schwarz\n\n\n\nCauchy-Schwarz Inequality\n\n\n\\(\\left(\\Er[XY]\\right)^2 \\leq \\Er[X^2] \\Er[Y^2]\\)"
  },
  {
    "objectID": "probability/probability.html#generated-sigma-field",
    "href": "probability/probability.html#generated-sigma-field",
    "title": "Probability",
    "section": "Generated \\(\\sigma\\)-field",
    "text": "Generated \\(\\sigma\\)-field\n\n\\(\\sigma(X)\\) is \\(\\sigma\\)-field generated by \\(X\\)\n\nsmallest \\(\\sigma\\)-field w.r.t. which \\(X\\) is measurable\n\\(\\sigma(X) = \\{X^{-1}(B): B \\in \\mathscr{B}(\\R)\\}\\)"
  },
  {
    "objectID": "probability/probability.html#information",
    "href": "probability/probability.html#information",
    "title": "Probability",
    "section": "Information",
    "text": "Information\n\n\\(\\forall E \\in \\sigma(X)\\), observing value \\(x\\) of \\(X\\), tells us whether \\(E\\) occurred\nif \\(\\sigma(X_1) \\subset \\sigma(X_2)\\), then \\(\\sigma(X_2)\\) has more information than \\(\\sigma(X_1)\\)\n\n\nExample 4.3 in Song (2021)."
  },
  {
    "objectID": "probability/probability.html#dependence",
    "href": "probability/probability.html#dependence",
    "title": "Probability",
    "section": "Dependence",
    "text": "Dependence\n\n\n\nTheorem 4.2\n\n\nSuppose \\(\\sigma(W) \\subset \\sigma(X)\\), then \\(\\exists\\) Borel measurable \\(g\\) s.t. \\(W=g(X)\\)\n\n\n\n\nProof in Çinlar (2011) chapter 2, section 4."
  },
  {
    "objectID": "probability/probability.html#independence-1",
    "href": "probability/probability.html#independence-1",
    "title": "Probability",
    "section": "Independence",
    "text": "Independence\n\n\n\nDefinition\n\n\n\nEvents \\(A_1, ..., A_m\\) are independent if for any sub-collection \\(A_{i_1}, ..., A_{i_s}\\) \\[\nP\\left(\\cap_{j=1}^s A_{i_j}\\right) = \\prod_{j=1}^s P(A_{i_j})\n\\]\n\\(\\sigma\\)-fields, \\(\\mathscr{F}_1, .., \\mathscr{F}_m \\subset \\mathscr{F}\\) are independent if for any \\(\\mathscr{F}_{i_1}, .., \\mathscr{F}_{i_s}\\) and \\(E_j \\in \\mathscr{F}_j\\), \\[\nP\\left(\\cap_{j=1}^s E_{i_j}\\right) = \\prod_{j=1}^s P(E_{i_j})\n\\]\nRandom variables \\(X_1, ..., X_m\\) are independent if \\(\\sigma(X_1), ..., \\sigma(X_m)\\) are independent"
  },
  {
    "objectID": "probability/probability.html#random-vectors",
    "href": "probability/probability.html#random-vectors",
    "title": "Probability",
    "section": "Random Vectors",
    "text": "Random Vectors\n\nmeasurable \\(X: \\Omega \\to \\R^n\\)\n\\(\\sigma(X) = \\{X^{-1}(B): B \\in \\mathscr{B}(\\R^n)\\} =\\) smallest \\(\\sigma\\)-field containing \\(\\cup_{i=1}^n \\sigma(X_i)\\)\n\n\n\n\nTheorem\n\n\nSuppose that \\(X=(X_1, X_2)\\) and \\(Y=(Y_1, Y_2)\\) are independent, then \\(f(X)\\) and \\(g(Y)\\) are independent\n\n\n\n\nAs promised, an easy way to show obvious independence without any tedious calculations."
  },
  {
    "objectID": "probability/probability.html#conditional-expectation",
    "href": "probability/probability.html#conditional-expectation",
    "title": "Probability",
    "section": "Conditional Expectation",
    "text": "Conditional Expectation\n\n\n\nDefinition\n\n\nLet \\(\\mathscr{G} \\subset \\mathscr{F}\\) be \\(\\sigma\\)-fields, \\(Y\\) a random variable with \\(\\Er |Y| < \\infty\\), then the conditional expectation of \\(Y\\) given \\(\\mathscr{G}\\) is \\(\\Er[Y|\\mathscr{G}](\\cdot): \\Omega \\to \\R\\) s.t.\n\n\\(\\Er[Y|\\mathscr{G}](\\cdot)\\) is \\(\\mathscr{G}\\) measurable\n\\(\\int_A \\Er[Y|\\mathscr{G}] dP = \\int_A Y dP\\) \\(\\forall A \\in \\mathscr{G}\\)\n\n\n\n\n\n\nEx: \\(\\{E_k\\}_{k=1}^m\\) partition of \\(\\Omega\\), let \\(\\mathscr{G} = \\sigma(\\{E_k\\}_{k=1}^m)\\)\n\n\\(\\Er[Y | \\mathscr{G}](\\omega) = \\sum_{k=1}^m c_k 1\\{\\omega \\in E_k\\}\\)\n\nExistence from Radon-Nikodym theorem\n\\(\\Er[Y|X] \\equiv \\Er[Y|\\sigma(X)]\\)"
  },
  {
    "objectID": "probability/probability.html#properties-of-conditional-expectation",
    "href": "probability/probability.html#properties-of-conditional-expectation",
    "title": "Probability",
    "section": "Properties of Conditional Expectation",
    "text": "Properties of Conditional Expectation\n\n\nIf \\(X\\) is \\(\\mathscr{G}\\) measurable, then \\(\\Er[XY| \\mathscr{G}] = X \\Er[Y|\\mathscr{G}]\\) a.e.\nIf \\(\\sigma(X) \\subset \\sigma(Z)\\), then \\(\\Er[XY|Z] = X \\Er[Y|Z]\\)\nIf \\(\\sigma(X) \\subset \\sigma(Z)\\), then \\(\\Er[\\Er[Y|Z]|X] = \\Er[Y|X]\\)\nIf \\(Y\\) and \\(X\\) are independent, then \\(\\Er[Y | X ] = \\Er[Y]\\)"
  },
  {
    "objectID": "probability/probability.html#erymathscrg-as-orthogonal-projection",
    "href": "probability/probability.html#erymathscrg-as-orthogonal-projection",
    "title": "Probability",
    "section": "\\(\\Er[Y|\\mathscr{G}]\\) as Orthogonal Projection",
    "text": "\\(\\Er[Y|\\mathscr{G}]\\) as Orthogonal Projection\n\n\n\nWarning\n\n\nLet \\((\\Omega, \\mathscr{F}, P)\\) be a probability space, \\(\\mathscr{G}\\) a sub \\(\\sigma\\)-field, then for any \\(Y \\in \\mathcal{L}^2(\\Omega, \\mathscr{F}, P) = \\{X: \\Omega \\to \\mathbb{R} \\text{ s.t. } X \\text{ }\\mathscr{F}\\text{-measurable, } \\int X^2 dP < \\infty \\}\\), \\[\n\\inf_{W \\in \\mathcal{L}^2(\\Omega, \\mathscr{G}, P)} \\Er[(Y-W)^2] = \\Er[ (Y - \\Er[Y | \\mathscr{G}])^2]\n\\]"
  },
  {
    "objectID": "probability/probability.html#conditional-measure",
    "href": "probability/probability.html#conditional-measure",
    "title": "Probability",
    "section": "Conditional Measure",
    "text": "Conditional Measure\n\n\n\nDefinition\n\n\nLet \\(\\mathscr{G}\\) be a sub \\(\\sigma\\)-field of \\(\\mathscr{F}\\). Tthe conditional probability measure given \\(\\mathscr{G}\\) is defined to be a map \\(P(\\cdot \\mid \\mathscr{G})(\\cdot ):\\mathscr{F}\\times \\Omega \\rightarrow [0,1]\\) such that\n\nFor each \\(A\\in \\mathscr{F}\\), \\(P(A \\mid \\mathscr{G})(\\cdot )=\\mathbf{E}\\left[ 1\\{\\omega \\in A\\} \\mid \\mathscr{G}\\right] (\\cdot )\\), a.e.\nfor each \\(\\omega \\in \\Omega\\), \\(P(\\cdot \\mid \\mathscr{G})(\\omega )\\) is a probability measure on \\((\\Omega ,\\mathscr{F}).\\)"
  },
  {
    "objectID": "probability/probability.html#conditional-independence",
    "href": "probability/probability.html#conditional-independence",
    "title": "Probability",
    "section": "Conditional Independence",
    "text": "Conditional Independence\n\n\n\nDefinition\n\n\n\nEvents \\(A_1, ..., A_m \\in \\mathscr{F}\\) are conditionally independent given \\(\\mathscr{G}\\) if for any sub-collection, \\[\nP\\left( \\cap_{j=1}^s A_{i_j} | \\mathscr{G} \\right) = \\prod_{j=1}^s P(A_{i_j} | \\mathscr{G})\n\\]\nSub \\(\\sigma\\)-fields \\(\\mathscr{F}_1, ..., \\mathscr{F}_m\\) are conditionally independent given \\(\\mathscr{G}\\) if for any sub-collection and events, \\(E_i \\in \\mathscr{F}_i\\), \\[\nP\\left( \\cap_{j=1}^s E_{i_j} | \\mathscr{G} \\right) = \\prod_{j=1}^s P(E_{i_j} | \\mathscr{G})\n\\]\nRandom variables \\(X_1, ..., X_m\\) are conditionally independent given \\(\\mathscr{G}\\) if \\(\\sigma(X_1), ..., \\sigma(X_m)\\) are conditionally independent given \\(\\mathscr{G}\\)"
  },
  {
    "objectID": "problemsets/01/ps01.html",
    "href": "problemsets/01/ps01.html",
    "title": "ECON 626: Problem Set 1",
    "section": "",
    "text": "Problem 2\nSong (2021) exercise 4.1.\nFor a collection \\(\\mathscr{C}\\) of sets, we write \\(\\sigma (\\mathscr{C})\\) to denote the smallest \\(\\sigma\\)-field that contains \\(\\mathscr{C}\\), and say that \\(\\sigma (\\mathscr{C})\\) is the \\(\\sigma\\)-field generated by \\(\\mathscr{C}\\).\n\nLet \\(X\\) be a random variable on \\((\\Omega ,\\mathscr{F})\\) and let \\(\\mathscr{G}\\) be the collection of the sets of the form \\(\\{\\omega \\in \\Omega :X(\\omega )\\in B\\}\\) with \\(B\\in \\mathscr{B}(\\mathbf{R})\\). Then show that \\(\\mathscr{G}\\) is a \\(\\sigma\\)-field.\nShow that \\(\\{X^{-1}(A):A\\in \\sigma (\\mathscr{C})\\}=\\sigma(\\{X^{-1}(A):A\\in \\mathscr{C}\\})\\) for any subset \\(\\mathscr{C}\\) of \\(\\mathscr{B}(\\mathbf{R})\\).\n\n\n\n\n\n\nReferences\n\nSong, Kyunchul. 2021. “Introduction to Econometrics.”\n\n\nVaart, Aad W, and Jon A Wellner. 1996. Weak Convergence and Empirical Processes. Springer."
  },
  {
    "objectID": "problemsets/02/ps02.html",
    "href": "problemsets/02/ps02.html",
    "title": "ECON 626: Problem Set 2",
    "section": "",
    "text": "Problem 1\nLet \\(\\Omega = \\{1, 2, 3, 4\\}\\), \\(\\mathscr{F} = 2^\\Omega\\), and \\(X = 1\\{\\omega > 2 \\}\\). What is \\(\\sigma(X)\\)?\n\n\nProblem 2\nLet \\(f: \\R^2 \\to \\R\\). Assume \\(f(\\cdot, y): \\R \\to \\R\\) is measurable for all \\(y : |y - y_0| < \\epsilon\\) for some \\(\\epsilon>0\\). Also assume that \\(f(x, \\dot): \\R \\to \\R\\) is differentiable at \\(y_0\\) for all \\(x \\in A \\subset \\R\\) and \\(\\left\\vert \\frac{\\partial f}{\\partial y}(x, y_0) \\right \\vert \\leq M(x)\\) for all \\(x \\in A\\) and \\(M(x)\\) is integrable. Show that \\[\n\\frac{d}{dy} \\int_A f(\\cdot, y) d\\mu \\vert_{y=y_0} = \\int_A \\frac{\\partial f}{\\partial y} f(\\cdot, y_0) d\\mu.\n\\]\n\n\nProblem 3\nLet \\(X: \\Omega \\to \\R\\), \\(W: \\Omega \\to \\R\\), \\(Z: \\Omega \\to \\R\\), and \\(D: \\Omega \\to \\{0, 1\\}\\) be random variables. Let \\(Y = D X + (1-D) W\\). Suppose that \\(Y\\), \\(D\\), and \\(Z\\) are observed, but \\(X\\) and \\(W\\) are not.\n\nSuppose \\(D\\) is independent of \\(X\\), \\(W\\). Then show that \\(\\Er[X - W]\\) is identified.\nSuppose \\(Z\\) is independent of \\(X\\) and \\(W\\), and \\(\\exists E_1, E_0 \\in \\sigma(Z)\\) such that \\(P(D=1 | E_1) = 1\\) and \\(P(D=0|E_0) = 1\\). Then show that \\(\\Er[X-W]\\) is identified."
  },
  {
    "objectID": "slides.html",
    "href": "slides.html",
    "title": "Slides",
    "section": "",
    "text": "Sep 15, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSep 22, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSep 14, 2022\n\n\nPaul Schrimpf\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSep 16, 2022\n\n\nPaul Schrimpf\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSep 14, 2022\n\n\nPaul Schrimpf\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\nNo matching items"
  },
  {
    "objectID": "syllabus626.html",
    "href": "syllabus626.html",
    "title": "Syllabus for ECON 626: Econometric Theory I",
    "section": "",
    "text": "Paul Schrimpf\n107 Iona\npaul.schrimpf@ubc.ca\nOffice Hours: Wednesday 11:30am-12:30pm\n\n\n\nYige Duan\nyige.duan@gmail.com\nOffice Hours: TBA\n\n\n\nMondays and Wednesdays 10:00am - 11:20am, Iona 633\n\n\n\nOur primary textbook will be notes written by Kyunchul Song. You can find them on Canvas. Other recommended (but not required) textbooks include:\n\nBruce Hansen (2022) Probability and Statistics for Economists and Econometrics\nFumio Hayashi (2000) Econometrics\nGeorge Casella and Roger L. Berger (2002) Statistical Inference\nTakeshi Amemiya (1985) Advanced Econometrics"
  },
  {
    "objectID": "syllabus626.html#grading",
    "href": "syllabus626.html#grading",
    "title": "Syllabus for ECON 626: Econometric Theory I",
    "section": "Grading",
    "text": "Grading\n\nProblem Sets (30%)\nThere will be 6-9 problem sets. A problem set with the lowest grade will be dropped from final grading.\n\n\nMidterm Exam (30%)\nGiven in class on Wednesday, October 26. Closed books and notes. There will be no make-up exam for midterm. When a student is excused from midterm exam, his or her grade will be based on reweighting of the problem sets (40%) and the final exam (60%).\n\n\nFinal Exam (40%)\nClosed books and notes."
  },
  {
    "objectID": "syllabus626.html#part-i-basics",
    "href": "syllabus626.html#part-i-basics",
    "title": "Syllabus for ECON 626: Econometric Theory I",
    "section": "Part I: Basics",
    "text": "Part I: Basics\n\nProbability\n\nRandom Variables, and Distributions\nConditional Expectations and Conditional Distributions\nFamily of Distributions\n\nBasics of Inference - Estimation - Hypothesis Testing"
  },
  {
    "objectID": "syllabus626.html#part-ii-generalized-linear-model",
    "href": "syllabus626.html#part-ii-generalized-linear-model",
    "title": "Syllabus for ECON 626: Econometric Theory I",
    "section": "Part II: Generalized Linear Model",
    "text": "Part II: Generalized Linear Model\n\nPreliminaries of Projection Geometry - Generalized Linear Models and Gauss-Markov Theorem - Tests of Linear Hypothesis"
  },
  {
    "objectID": "syllabus626.html#part-iii-tools-of-asymptotic-theory",
    "href": "syllabus626.html#part-iii-tools-of-asymptotic-theory",
    "title": "Syllabus for ECON 626: Econometric Theory I",
    "section": "Part III: Tools of Asymptotic Theory",
    "text": "Part III: Tools of Asymptotic Theory\n\nModes of Convergence\nSlutsky’s Lemma/Continuous Mapping Theorem\nDelta Methods"
  },
  {
    "objectID": "syllabus626.html#part-v-linear-models-with-endogeneity",
    "href": "syllabus626.html#part-v-linear-models-with-endogeneity",
    "title": "Syllabus for ECON 626: Econometric Theory I",
    "section": "Part V: Linear Models with Endogeneity",
    "text": "Part V: Linear Models with Endogeneity\n\nIdentification and Endogeneity\nIdentification through IV and Inference\n\n\n\n\n\n\n\nUBC values and policies\n\n\n\nUBC provides resources to support student learning and to maintain healthy lifestyles but recognizes that sometimes crises arise and so there are additional resources to access including those for survivors of sexual violence. UBC values respect for the person and ideas of all members of the academic community. Harassment and discrimination are not tolerated nor is suppression of academic freedom. UBC provides appropriate accommodation for students with disabilities and for religious and cultural observances. UBC values academic honesty and students are expected to acknowledge the ideas generated by others and to uphold the highest academic standards in all of their actions. Details of the policies and how to access support are available here (https://senate.ubc.ca/policiesresources-support-student-success )"
  }
]